import os
import time
import hashlib
import logging
import requests
from update_pipeline import main as run_pipeline

# í™˜ê²½ ì„¤ì •
RDF_FILE = "./ontology/RDF_Forwarding.xml"  # ê°ì§€í•  RDF/TTL/OWL íŒŒì¼ëª…
FUSEKI_UPDATE_URL = "http://3.36.178.68:3030/dataset/data?graph=default"  # Fuseki ë°ì´í„°ì…‹ ì£¼ì†Œ
CHECK_INTERVAL = 10  # ë³€ê²½ ê°ì§€ ì£¼ê¸° (ì´ˆ)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("rdf_watch.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

def get_file_hash(path):
    with open(path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def update_fuseki(rdf_path):
    with open(rdf_path, "rb") as f:
        headers = {"Content-Type": "text/turtle"}
        res = requests.post(FUSEKI_UPDATE_URL, headers=headers, data=f)
        res.raise_for_status()
    logging.info("âœ… Fusekiì— RDF ì—…ë¡œë“œ ì™„ë£Œ")

def watch_rdf_file():
    if not os.path.exists(RDF_FILE):
        logging.error(f"âŒ {RDF_FILE} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    last_hash = get_file_hash(RDF_FILE)
    logging.info("ğŸ‘€ RDF íŒŒì¼ ë³€ê²½ ê°ì§€ ì‹œì‘...")

    while True:
        try:
            time.sleep(CHECK_INTERVAL)
            current_hash = get_file_hash(RDF_FILE)
            if current_hash != last_hash:
                logging.info("ğŸ”„ RDF íŒŒì¼ ë³€ê²½ ê°ì§€ë¨. ì—…ë°ì´íŠ¸ ì‹¤í–‰ ì¤‘...")
                update_fuseki(RDF_FILE)
                run_pipeline()  # update_pipeline.pyì˜ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
                last_hash = current_hash
                logging.info("âœ… ë³€ê²½ ì²˜ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logging.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    watch_rdf_file()
